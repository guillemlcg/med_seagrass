{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Uber NCR Ride Bookings Analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook provides a comprehensive analysis of Uber ride booking data from the National Capital Region (NCR) of India. The analysis explores ride patterns, customer behavior, operational efficiency, and business insights from a dataset containing 150,000 ride records with 21 features.\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "- **Source**: NCR Ride Bookings Dataset\n",
    "- **Size**: 150,000 records × 21 columns\n",
    "- **Format**: CSV\n",
    "- **Time Period**: 2024 (January - December)\n",
    "- **Geographic Coverage**: National Capital Region (Delhi, Gurgaon, Noida, etc.)\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Temporal Data**: Date, Time information for ride analysis\n",
    "- **Booking Information**: Booking ID, Status, Customer ID\n",
    "- **Vehicle Data**: Vehicle Type (Auto, Bike, eBike, Go Sedan, Go Mini, Premier Sedan)\n",
    "- **Geographic Data**: Pickup and Drop locations\n",
    "- **Performance Metrics**: Average Vehicle Turn Around Time (VTAT), Customer Turn Around Time (CTAT)\n",
    "- **Financial Data**: Booking Value, Payment Methods\n",
    "- **Quality Metrics**: Driver and Customer Ratings, Ride Distance\n",
    "- **Operational Data**: Cancellations, Incomplete rides with reasons\n",
    "\n",
    "## Analysis Workflow\n",
    "\n",
    "1. **Data Loading & Initial Setup**\n",
    "2. **Data Preprocessing & Cleaning**\n",
    "3. **Exploratory Data Analysis (EDA)**\n",
    "4. **Temporal Pattern Analysis**\n",
    "5. **Business Performance Analysis**\n",
    "6. **Customer Segmentation (RFM Analysis)**\n",
    "7. **Key Insights & Recommendations**\n",
    "\n",
    "## Business Questions Addressed\n",
    "\n",
    "- What are the key temporal patterns in ride demand?\n",
    "- Which vehicle types perform best in different scenarios?\n",
    "- What factors contribute to ride cancellations and incompletions?\n",
    "- How do customer ratings correlate with operational metrics?\n",
    "- What are the main revenue drivers and optimization opportunities?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "libraries_section",
   "metadata": {},
   "source": [
    "## 1. Library Imports and Setup\n",
    "\n",
    "### Purpose:\n",
    "Import essential libraries for data analysis, visualization, and statistical computing.\n",
    "\n",
    "### Key Components:\n",
    "- **pandas**: Data manipulation and analysis framework\n",
    "- **numpy**: Numerical computing and array operations\n",
    "- **matplotlib**: Basic plotting and visualization\n",
    "- **seaborn**: Statistical data visualization\n",
    "- **datetime**: Date and time handling utilities\n",
    "- **warnings**: Control warning messages for cleaner output\n",
    "\n",
    "### Configuration:\n",
    "- Display settings optimized for wide datasets\n",
    "- Warning suppression for cleaner notebook output\n",
    "- Version information for reproducibility\n",
    "\n",
    "### Notes:\n",
    "- All libraries are standard for data science workflows\n",
    "- Configuration ensures optimal viewing of large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "libraries_import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for data analysis and visualization\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np   # Numerical computing and array operations\n",
    "import matplotlib.pyplot as plt  # Basic plotting functionality\n",
    "import seaborn as sns           # Statistical visualization\n",
    "from datetime import datetime   # Date and time handling\n",
    "import warnings                 # Warning control\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better data viewing\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)        # Auto-adjust width\n",
    "pd.set_option('display.max_colwidth', 50)   # Limit column width for readability\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading_section",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "### Purpose:\n",
    "Load the NCR ride bookings dataset from CSV file and perform initial data quality assessment.\n",
    "\n",
    "### Key Steps:\n",
    "- Read CSV file using `pd.read_csv()` with proper path handling\n",
    "- Display basic dataset information (shape, memory usage)\n",
    "- Store data in `df` variable for consistent reference\n",
    "\n",
    "### Variables/Functions:\n",
    "- `df`: Main DataFrame containing all ride booking data\n",
    "- `pd.read_csv()`: Pandas function to read CSV files\n",
    "- `.shape`: Returns (rows, columns) tuple\n",
    "- `.memory_usage()`: Calculates memory consumption\n",
    "\n",
    "### Expected Output:\n",
    "- Dataset dimensions: 150,000 rows × 21 columns\n",
    "- Memory usage: ~24MB\n",
    "\n",
    "### Notes:\n",
    "- Using raw string to handle file path correctly\n",
    "- Memory usage indicates manageable dataset size for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NCR ride bookings dataset\n",
    "# Using raw string to handle file path correctly\n",
    "df = pd.read_csv(r'data/ncr_ride_bookings.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "display_config_section", 
   "metadata": {},
   "source": [
    "## 3. Display Configuration\n",
    "\n",
    "### Purpose:\n",
    "Configure pandas display options for optimal data viewing during analysis.\n",
    "\n",
    "### Key Steps:\n",
    "- Set `display.max_columns` to None to show all columns in DataFrame output\n",
    "- Comment out `display.max_rows` setting to use default row limiting\n",
    "\n",
    "### Variables/Functions:\n",
    "- `pd.set_option()`: Pandas function to configure display settings\n",
    "- `display.max_columns`: Option controlling maximum columns displayed\n",
    "- `display.max_rows`: Option controlling maximum rows displayed\n",
    "\n",
    "### Notes:\n",
    "- Essential for viewing wide datasets with many columns\n",
    "- Row limiting prevents overwhelming output in large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "display_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pandas display options for optimal data viewing\n",
    "pd.set_option('display.max_columns', None)  # Show all columns when displaying DataFrames\n",
    "# pd.set_option('display.max_rows', None)   # Uncomment to show all rows (use cautiously with large datasets)\n",
    "\n",
    "print(\"Display configuration set: All columns will be shown\")\n",
    "print(\"Row display uses default limiting for better performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing_section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Preprocessing and Initial Exploration\n",
    "\n",
    "## 4. Initial Data Examination\n",
    "\n",
    "### Purpose:\n",
    "Examine the first 20 rows of the dataset to understand data structure, format, and identify potential data quality issues.\n",
    "\n",
    "### Key Steps:\n",
    "- Display first 20 rows using `df.head(20)`\n",
    "- Observe data types, missing values, and patterns\n",
    "- Identify columns with quoted values that may need cleaning\n",
    "\n",
    "### Variables/Functions:\n",
    "- `df.head(20)`: Displays first 20 rows of DataFrame\n",
    "\n",
    "### Notes:\n",
    "- Some columns contain quoted strings (e.g., \"CNR5884300\") that may need cleaning\n",
    "- Many NaN values visible, indicating missing data that needs handling\n",
    "- Mixed data types require validation and potential conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "data_examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 20 rows to understand data structure and identify patterns\n",
    "# This helps us understand:\n",
    "# - Data types and formats\n",
    "# - Missing values distribution  \n",
    "# - String formatting issues (quoted values)\n",
    "# - Range and variety of data values\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "column_analysis_section",
   "metadata": {},
   "source": [
    "## 5. Column Structure Analysis\n",
    "\n",
    "### Purpose:\n",
    "Examine the column names and structure to understand all available features in the dataset.\n",
    "\n",
    "### Key Steps:\n",
    "- Use `df.columns` to display all column names\n",
    "- Identify column categories (temporal, geographic, performance, financial, etc.)\n",
    "\n",
    "### Variables/Functions:\n",
    "- `df.columns`: Returns Index object containing all column names\n",
    "\n",
    "### Column Categories Identified:\n",
    "- **Temporal**: Date, Time  \n",
    "- **Identifiers**: Booking ID, Customer ID\n",
    "- **Status**: Booking Status, cancellation flags\n",
    "- **Geographic**: Pickup Location, Drop Location\n",
    "- **Vehicle**: Vehicle Type\n",
    "- **Performance**: Avg VTAT, Avg CTAT, ratings\n",
    "- **Financial**: Booking Value, Payment Method\n",
    "- **Operational**: Ride Distance, cancellation reasons\n",
    "\n",
    "### Notes:\n",
    "- 21 total columns providing comprehensive ride information\n",
    "- Good mix of categorical and numerical features\n",
    "- Several conditional columns (cancellation reasons only populated when applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "column_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names to understand feature structure\n",
    "print(\"Dataset Columns:\")\n",
    "print(\"=\"*50)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "    \n",
    "print(f\"\\nTotal columns: {len(df.columns)}\")\n",
    "\n",
    "# Also show the Index object for reference\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_info_section",
   "metadata": {},
   "source": [
    "## 6. Dataset Information and Data Types\n",
    "\n",
    "### Purpose:\n",
    "Analyze dataset structure, memory usage, data types, and missing values to understand data quality and preprocessing needs.\n",
    "\n",
    "### Key Steps:\n",
    "- Use `df.info()` to get comprehensive dataset overview\n",
    "- Identify data types for each column\n",
    "- Count non-null values to identify missing data patterns\n",
    "- Calculate memory usage for performance considerations\n",
    "\n",
    "### Variables/Functions:\n",
    "- `df.info()`: Provides concise summary of DataFrame including data types and memory usage\n",
    "\n",
    "### Key Findings Expected:\n",
    "- **Dataset Size**: 150,000 entries × 21 columns\n",
    "- **Memory Usage**: ~24.0+ MB\n",
    "- **Data Types**: Mix of object (12) and float64 (9) types\n",
    "- **Missing Data**: Significant missing values in performance metrics\n",
    "\n",
    "### Data Quality Issues Identified:\n",
    "- Conditional columns have expected missing values (cancellation reasons)\n",
    "- Performance metrics (VTAT, CTAT) missing for failed bookings\n",
    "- Financial data only available for completed rides\n",
    "\n",
    "### Notes:\n",
    "- Missing values are largely structured and expected based on booking status\n",
    "- Object types may need cleaning (quoted strings) and conversion\n",
    "- Float64 precision may be excessive for some integer-like data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dataset_info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive information about the dataset\n",
    "# This includes data types, non-null counts, and memory usage\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMISSING DATA SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "# Show only columns with missing data\n",
    "missing_summary_filtered = missing_summary[missing_summary['Missing Count'] > 0]\n",
    "missing_summary_filtered = missing_summary_filtered.sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_summary_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_preprocessing_section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Data Preprocessing and Feature Engineering\n",
    "\n",
    "## 7. Data Cleaning and Feature Creation\n",
    "\n",
    "### Purpose:\n",
    "Clean data inconsistencies, convert data types, and create temporal features for comprehensive analysis.\n",
    "\n",
    "### Key Steps:\n",
    "- Remove quotes from ID columns\n",
    "- Create datetime objects from Date and Time columns\n",
    "- Extract temporal features (Hour, Day of Week, Month, etc.)\n",
    "- Create categorical time periods and weekend flags\n",
    "\n",
    "### Variables/Functions:\n",
    "- `str.replace()`: Remove unwanted characters\n",
    "- `pd.to_datetime()`: Convert strings to datetime objects\n",
    "- DateTime accessors: `.dt.hour`, `.dt.dayofweek`, etc.\n",
    "\n",
    "### New Features Created:\n",
    "- DateTime: Combined date and time column\n",
    "- Hour: Hour of day (0-23)\n",
    "- Day of Week: Day number (0=Monday, 6=Sunday)\n",
    "- Month: Month number (1-12)\n",
    "- Is Weekend: Boolean flag for Saturday/Sunday\n",
    "- Time Period: Categorical (Morning, Afternoon, Evening, Night)\n",
    "\n",
    "### Notes:\n",
    "- Preserves original columns while adding engineered features\n",
    "- Validates datetime conversion success\n",
    "- Creates foundation for temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "data_preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime column and temporal features\n",
    "# First, clean the ID columns by removing quotes\n",
    "df['Booking ID'] = df['Booking ID'].str.replace('\"', '')\n",
    "df['Customer ID'] = df['Customer ID'].str.replace('\"', '')\n",
    "\n",
    "# Create datetime column from Date and Time\n",
    "df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "\n",
    "# Extract temporal features for analysis\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "df['Day of Week'] = df['DateTime'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df['Day Name'] = df['DateTime'].dt.day_name()\n",
    "df['Month'] = df['DateTime'].dt.month\n",
    "df['Month Name'] = df['DateTime'].dt.month_name()\n",
    "df['Quarter'] = df['DateTime'].dt.quarter\n",
    "df['Week of Year'] = df['DateTime'].dt.isocalendar().week\n",
    "df['Is Weekend'] = df['Day of Week'].isin([5, 6])  # Saturday=5, Sunday=6\n",
    "\n",
    "# Create time period categories for business analysis\n",
    "def categorize_time_period(hour):\n",
    "    \"\"\"Categorize hours into meaningful business time periods\"\"\"\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['Time Period'] = df['Hour'].apply(categorize_time_period)\n",
    "\n",
    "print(f\"Data preprocessing completed!\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"New temporal features added: Hour, Day of Week, Month, Time Period, etc.\")\n",
    "print(f\"Date range: {df['DateTime'].min()} to {df['DateTime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical_analysis_section",
   "metadata": {},
   "source": [
    "## 8. Descriptive Statistical Analysis\n",
    "\n",
    "### Purpose:\n",
    "Generate comprehensive statistical summaries for numerical columns to understand data distributions, central tendencies, and identify potential outliers.\n",
    "\n",
    "### Key Steps:\n",
    "- Calculate summary statistics using `describe()`\n",
    "- Analyze key business metrics (booking values, distances, ratings)\n",
    "- Identify data quality issues and outliers\n",
    "- Generate business insights from statistical patterns\n",
    "\n",
    "### Variables/Functions:\n",
    "- `df.describe()`: Summary statistics for numerical columns\n",
    "- `df.select_dtypes()`: Filter columns by data type\n",
    "- Statistical measures: mean, median, std, percentiles\n",
    "\n",
    "### Key Metrics Analyzed:\n",
    "- **Booking Value**: Revenue distribution and outliers\n",
    "- **Ride Distance**: Trip length patterns\n",
    "- **VTAT/CTAT**: Service efficiency metrics\n",
    "- **Ratings**: Customer and driver satisfaction\n",
    "\n",
    "### Expected Insights:\n",
    "- Revenue concentration and pricing patterns\n",
    "- Service efficiency benchmarks\n",
    "- Customer satisfaction levels\n",
    "- Operational performance indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "statistical_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive statistical analysis of numerical columns\n",
    "print(\"DESCRIPTIVE STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display descriptive statistics for all numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "business_insights_section",
   "metadata": {},
   "source": [
    "## 9. Key Statistical Insights\n",
    "\n",
    "### Purpose:\n",
    "Extract and present key business insights from the statistical analysis using numpy for additional calculations.\n",
    "\n",
    "### Key Steps:\n",
    "- Calculate advanced statistics using numpy functions\n",
    "- Generate business-relevant insights\n",
    "- Identify performance benchmarks\n",
    "- Highlight areas for operational improvement\n",
    "\n",
    "### Variables/Functions:\n",
    "- `np.mean()`, `np.median()`: Central tendency measures\n",
    "- `np.std()`, `np.var()`: Variability measures\n",
    "- `np.percentile()`: Percentile calculations\n",
    "\n",
    "### Business Applications:\n",
    "- Pricing strategy insights\n",
    "- Service quality benchmarks\n",
    "- Operational efficiency targets\n",
    "- Customer satisfaction metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "numpy_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced statistical analysis using numpy for business insights\n",
    "print(\"ADVANCED STATISTICAL INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Booking Value Analysis using numpy\n",
    "booking_values = df['Booking Value'].dropna().values\n",
    "if len(booking_values) > 0:\n",
    "    print(\"💰 BOOKING VALUE INSIGHTS:\")\n",
    "    print(f\"   • Mean: ₹{np.mean(booking_values):.2f}\")\n",
    "    print(f\"   • Median: ₹{np.median(booking_values):.2f}\")\n",
    "    print(f\"   • Standard Deviation: ₹{np.std(booking_values):.2f}\")\n",
    "    print(f\"   • 25th Percentile: ₹{np.percentile(booking_values, 25):.2f}\")\n",
    "    print(f\"   • 75th Percentile: ₹{np.percentile(booking_values, 75):.2f}\")\n",
    "    print(f\"   • 95th Percentile: ₹{np.percentile(booking_values, 95):.2f}\")\n",
    "    print(f\"   • Variance: {np.var(booking_values):.2f}\")\n",
    "\n",
    "# Distance Analysis\n",
    "distances = df['Ride Distance'].dropna().values\n",
    "if len(distances) > 0:\n",
    "    print(f\"\\n🚗 RIDE DISTANCE INSIGHTS:\")\n",
    "    print(f\"   • Average distance: {np.mean(distances):.2f} km\")\n",
    "    print(f\"   • Median distance: {np.median(distances):.2f} km\")\n",
    "    print(f\"   • Distance variability: {np.std(distances):.2f} km\")\n",
    "    print(f\"   • Short rides (<10km): {np.sum(distances < 10) / len(distances) * 100:.1f}%\")\n",
    "    print(f\"   • Long rides (>50km): {np.sum(distances > 50) / len(distances) * 100:.1f}%\")\n",
    "\n",
    "# Rating Analysis\n",
    "driver_ratings = df['Driver Ratings'].dropna().values\n",
    "customer_ratings = df['Customer Rating'].dropna().values\n",
    "\n",
    "if len(driver_ratings) > 0 and len(customer_ratings) > 0:\n",
    "    print(f\"\\n⭐ RATING INSIGHTS:\")\n",
    "    print(f\"   • Average driver rating: {np.mean(driver_ratings):.2f}/5.0\")\n",
    "    print(f\"   • Average customer rating: {np.mean(customer_ratings):.2f}/5.0\")\n",
    "    print(f\"   • High driver ratings (4.0+): {np.sum(driver_ratings >= 4.0) / len(driver_ratings) * 100:.1f}%\")\n",
    "    print(f\"   • High customer ratings (4.0+): {np.sum(customer_ratings >= 4.0) / len(customer_ratings) * 100:.1f}%\")\n",
    "    print(f\"   • Rating correlation: {np.corrcoef(driver_ratings, customer_ratings)[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal_business_analysis_section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Advanced Business Analysis\n",
    "\n",
    "## 10. Temporal Revenue Analysis\n",
    "\n",
    "### Purpose:\n",
    "Analyze revenue patterns across different time dimensions to identify peak periods, seasonal trends, and optimization opportunities for pricing strategies.\n",
    "\n",
    "### Key Steps:\n",
    "- Calculate daily booking value patterns\n",
    "- Analyze monthly revenue trends and seasonality\n",
    "- Compare weekend vs weekday performance\n",
    "- Generate actionable pricing recommendations\n",
    "\n",
    "### Variables/Functions:\n",
    "- `groupby()` with temporal dimensions\n",
    "- Revenue aggregation and trend analysis\n",
    "- Statistical comparisons between time periods\n",
    "\n",
    "### Business Applications:\n",
    "- Dynamic pricing strategy development\n",
    "- Resource allocation optimization\n",
    "- Marketing campaign timing\n",
    "- Seasonal planning and forecasting\n",
    "\n",
    "### Expected Insights:\n",
    "- Peak revenue periods for premium pricing\n",
    "- Low-demand periods requiring promotional pricing\n",
    "- Seasonal patterns for strategic planning\n",
    "- Weekend vs weekday revenue differentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal_revenue_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced temporal revenue analysis for business insights\n",
    "print(\"TEMPORAL REVENUE ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Daily booking value analysis\n",
    "daily_booking_value = df.groupby(['Day Name']).agg({\n",
    "    'Booking Value': ['sum', 'mean', 'count'],\n",
    "    'Booking Status': lambda x: (x == 'Completed').sum()\n",
    "}).round(2)\n",
    "\n",
    "daily_booking_value.columns = ['Total Booking Value', 'Avg Booking Value', 'Total Bookings', 'Completed Bookings']\n",
    "\n",
    "# Reorder by day of week for logical flow\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_booking_value = daily_booking_value.reindex(day_order)\n",
    "\n",
    "print(\"📊 DAILY REVENUE PERFORMANCE:\")\n",
    "display(daily_booking_value)\n",
    "\n",
    "# Calculate weekend vs weekday performance\n",
    "weekend_avg = daily_booking_value.loc[['Saturday', 'Sunday'], 'Total Booking Value'].mean()\n",
    "weekday_avg = daily_booking_value.loc[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'], 'Total Booking Value'].mean()\n",
    "\n",
    "print(f\"\\n📈 WEEKEND VS WEEKDAY ANALYSIS:\")\n",
    "print(f\"   • Weekend average revenue: ₹{weekend_avg:,.0f} per day\")\n",
    "print(f\"   • Weekday average revenue: ₹{weekday_avg:,.0f} per day\")\n",
    "print(f\"   • Weekend premium: {((weekend_avg / weekday_avg) - 1) * 100:.1f}%\")\n",
    "\n",
    "# Monthly revenue trends\n",
    "monthly_sorted = df.groupby('Month')['Booking Value'].sum().sort_values(ascending=False)\n",
    "print(f\"\\n📅 MONTHLY REVENUE RANKING:\")\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "for i, (month, revenue) in enumerate(monthly_sorted.head(6).items(), 1):\n",
    "    print(f\"   {i}. {month_names[month-1]}: ₹{revenue:,.0f}\")\n",
    "\n",
    "print(f\"\\n💰 STRATEGIC PRICING RECOMMENDATIONS:\")\n",
    "if weekend_avg > weekday_avg:\n",
    "    print(f\"   • Implement premium weekend pricing (+{((weekend_avg / weekday_avg) - 1) * 100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   • Create weekend promotions to boost demand\")\n",
    "\n",
    "print(f\"\\n🎯 PROMOTIONAL CAMPAIGN OPPORTUNITIES:\")\n",
    "low_months = monthly_sorted.tail(3).index.tolist()\n",
    "print(f\"   • Intensify marketing in months: {[month_names[m-1] for m in low_months]}\")\n",
    "print(f\"   • Strategic discounts on {daily_booking_value['Total Booking Value'].idxmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly_cohort_analysis_section",
   "metadata": {},
   "source": [
    "## 11. Monthly Booking Status Analysis\n",
    "\n",
    "### Purpose:\n",
    "Analyze booking completion patterns across months to identify seasonal service quality trends and operational challenges.\n",
    "\n",
    "### Key Steps:\n",
    "- Create monthly cohort analysis of booking statuses\n",
    "- Calculate completion rates by month\n",
    "- Identify seasonal operational patterns\n",
    "- Generate operational improvement recommendations\n",
    "\n",
    "### Variables/Functions:\n",
    "- `pivot_table()` for cross-tabulation analysis\n",
    "- Percentage calculations for comparative analysis\n",
    "- Time-series pattern identification\n",
    "\n",
    "### Key Metrics:\n",
    "- Monthly completion rates\n",
    "- Cancellation pattern variations\n",
    "- Seasonal service quality trends\n",
    "- Driver availability patterns\n",
    "\n",
    "### Business Applications:\n",
    "- Seasonal resource planning\n",
    "- Service quality monitoring\n",
    "- Driver recruitment timing\n",
    "- Operational efficiency improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "monthly_cohort_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly booking behavior cohort analysis\n",
    "print(\"MONTHLY BOOKING STATUS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create monthly cohort table showing booking status distribution\n",
    "monthly_cohort = df.groupby(['Month', 'Booking Status']).size().unstack(fill_value=0)\n",
    "monthly_cohort_pct = monthly_cohort.div(monthly_cohort.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"📊 MONTHLY BOOKING STATUS DISTRIBUTION (%)\")\n",
    "display(monthly_cohort_pct.round(2))\n",
    "\n",
    "# Calculate key insights\n",
    "completion_rates = monthly_cohort_pct['Completed'] if 'Completed' in monthly_cohort_pct.columns else pd.Series()\n",
    "best_completion_month = completion_rates.idxmax() if not completion_rates.empty else None\n",
    "worst_completion_month = completion_rates.idxmin() if not completion_rates.empty else None\n",
    "\n",
    "if best_completion_month and worst_completion_month:\n",
    "    print(f\"\\n📈 KEY OPERATIONAL INSIGHTS:\")\n",
    "    print(f\"   • Best completion rate: Month {best_completion_month} ({completion_rates[best_completion_month]:.1f}%)\")\n",
    "    print(f\"   • Worst completion rate: Month {worst_completion_month} ({completion_rates[worst_completion_month]:.1f}%)\")\n",
    "    print(f\"   • Performance variation: {completion_rates.max() - completion_rates.min():.1f} percentage points\")\n",
    "    \n",
    "    # Seasonal pattern analysis\n",
    "    q1_completion = completion_rates[1:4].mean()  # Jan-Mar\n",
    "    q2_completion = completion_rates[4:7].mean()  # Apr-Jun\n",
    "    q3_completion = completion_rates[7:10].mean()  # Jul-Sep\n",
    "    q4_completion = completion_rates[10:13].mean()  # Oct-Dec\n",
    "    \n",
    "    print(f\"\\n🗓️ QUARTERLY COMPLETION RATES:\")\n",
    "    print(f\"   • Q1 (Jan-Mar): {q1_completion:.1f}%\")\n",
    "    print(f\"   • Q2 (Apr-Jun): {q2_completion:.1f}%\")\n",
    "    print(f\"   • Q3 (Jul-Sep): {q3_completion:.1f}%\")\n",
    "    print(f\"   • Q4 (Oct-Dec): {q4_completion:.1f}%\")\n",
    "\n",
    "# Driver availability analysis\n",
    "no_driver_rates = monthly_cohort_pct['No Driver Found'] if 'No Driver Found' in monthly_cohort_pct.columns else pd.Series()\n",
    "if not no_driver_rates.empty:\n",
    "    worst_availability_month = no_driver_rates.idxmax()\n",
    "    print(f\"\\n🚗 DRIVER AVAILABILITY INSIGHTS:\")\n",
    "    print(f\"   • Worst availability: Month {worst_availability_month} ({no_driver_rates[worst_availability_month]:.1f}% no driver found)\")\n",
    "    print(f\"   • Average no-driver rate: {no_driver_rates.mean():.1f}%\")\n",
    "    print(f\"   • Recommendation: Increase driver incentives in Month {worst_availability_month}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "customer_segmentation_section",
   "metadata": {},
   "source": [
    "## 12. Customer Segmentation (RFM Analysis)\n",
    "\n",
    "### Purpose:\n",
    "Implement RFM (Recency, Frequency, Monetary) analysis to segment customers based on their booking behavior and value contribution.\n",
    "\n",
    "### Key Steps:\n",
    "- Calculate Recency (days since last booking)\n",
    "- Calculate Frequency (number of completed bookings)\n",
    "- Calculate Monetary value (total booking value)\n",
    "- Create RFM scores and customer segments\n",
    "\n",
    "### Variables/Functions:\n",
    "- `groupby()` aggregations for customer metrics\n",
    "- `pd.qcut()` for percentile-based scoring\n",
    "- Customer lifecycle analysis\n",
    "\n",
    "### RFM Components:\n",
    "- **Recency**: How recently did the customer book?\n",
    "- **Frequency**: How often does the customer book?\n",
    "- **Monetary**: How much does the customer spend?\n",
    "\n",
    "### Customer Segments:\n",
    "- Champions (High RFM scores)\n",
    "- Loyal Customers (High frequency)\n",
    "- At-Risk Customers (Low recency)\n",
    "- Lost Customers (Very low recency)\n",
    "\n",
    "### Business Applications:\n",
    "- Targeted marketing campaigns\n",
    "- Customer retention strategies\n",
    "- Loyalty program design\n",
    "- Revenue optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rfm_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer RFM (Recency, Frequency, Monetary) Analysis\n",
    "print(\"CUSTOMER SEGMENTATION - RFM ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate RFM metrics for completed rides only\n",
    "customer_metrics = df[df['Booking Status'] == 'Completed'].groupby('Customer ID').agg({\n",
    "    'DateTime': lambda x: (df['DateTime'].max() - x.max()).days,  # Recency\n",
    "    'Booking ID': 'count',  # Frequency\n",
    "    'Booking Value': 'sum'   # Monetary\n",
    "}).rename(columns={'DateTime': 'Recency', 'Booking ID': 'Frequency', 'Booking Value': 'Monetary'})\n",
    "\n",
    "# Remove customers with missing monetary values\n",
    "customer_metrics = customer_metrics.dropna()\n",
    "\n",
    "if len(customer_metrics) > 0:\n",
    "    print(f\"Total customers analyzed: {len(customer_metrics):,}\")\n",
    "    \n",
    "    # Create RFM scores (1-5 scale, 5 being best)\n",
    "    customer_metrics['R_Score'] = pd.qcut(customer_metrics['Recency'], 5, labels=[5,4,3,2,1])  # Lower recency = higher score\n",
    "    customer_metrics['F_Score'] = pd.qcut(customer_metrics['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
    "    customer_metrics['M_Score'] = pd.qcut(customer_metrics['Monetary'], 5, labels=[1,2,3,4,5])\n",
    "    \n",
    "    # Create combined RFM score\n",
    "    customer_metrics['RFM_Score'] = (customer_metrics['R_Score'].astype(str) + \n",
    "                                    customer_metrics['F_Score'].astype(str) + \n",
    "                                    customer_metrics['M_Score'].astype(str))\n",
    "    \n",
    "    print(\"\\n📊 RFM CUSTOMER SEGMENTS:\")\n",
    "    display(customer_metrics.head(10))\n",
    "    \n",
    "    # Calculate segment statistics\n",
    "    print(f\"\\n💎 CUSTOMER VALUE INSIGHTS:\")\n",
    "    print(f\"   • Average recency: {customer_metrics['Recency'].mean():.0f} days\")\n",
    "    print(f\"   • Average frequency: {customer_metrics['Frequency'].mean():.1f} bookings\")\n",
    "    print(f\"   • Average monetary value: ₹{customer_metrics['Monetary'].mean():.0f}\")\n",
    "    \n",
    "    # High-value customer analysis\n",
    "    high_value_customers = customer_metrics[\n",
    "        (customer_metrics['F_Score'] >= 4) & (customer_metrics['M_Score'] >= 4)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n🏆 HIGH-VALUE CUSTOMER INSIGHTS:\")\n",
    "    print(f\"   • High-value customers: {len(high_value_customers):,} ({len(high_value_customers)/len(customer_metrics)*100:.1f}%)\")\n",
    "    if len(high_value_customers) > 0:\n",
    "        print(f\"   • Avg spending per high-value customer: ₹{high_value_customers['Monetary'].mean():.0f}\")\n",
    "        print(f\"   • Revenue from top customers: ₹{high_value_customers['Monetary'].sum():,.0f}\")\n",
    "        print(f\"   • Revenue share from top customers: {high_value_customers['Monetary'].sum()/customer_metrics['Monetary'].sum()*100:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  Insufficient data for RFM analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive_insights_section",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Comprehensive Business Insights and Recommendations\n",
    "\n",
    "## 13. Executive Summary and Strategic Recommendations\n",
    "\n",
    "### Purpose:\n",
    "Synthesize all analysis results into actionable business insights, strategic recommendations, and implementation roadmap for the NCR ride booking operations.\n",
    "\n",
    "### Key Analysis Areas Covered:\n",
    "- **Operational Performance**: Service completion rates, efficiency metrics\n",
    "- **Financial Performance**: Revenue patterns, pricing opportunities\n",
    "- **Customer Behavior**: Segmentation, satisfaction, retention\n",
    "- **Temporal Patterns**: Peak periods, seasonality, demand forecasting\n",
    "- **Quality Metrics**: Ratings, cancellations, service reliability\n",
    "\n",
    "### Strategic Framework:\n",
    "1. **Immediate Actions** (0-3 months): Quick wins and urgent fixes\n",
    "2. **Medium-term Initiatives** (3-12 months): Process improvements\n",
    "3. **Long-term Strategy** (1+ years): Market expansion and innovation\n",
    "\n",
    "### Success Metrics:\n",
    "- Completion rate improvement targets\n",
    "- Revenue growth objectives\n",
    "- Customer satisfaction benchmarks\n",
    "- Operational efficiency KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "executive_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Executive Summary and Business Recommendations\n",
    "print(\"🎯 EXECUTIVE SUMMARY & STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate key performance indicators\n",
    "total_bookings = len(df)\n",
    "completion_rate = (df['Booking Status'] == 'Completed').mean() * 100\n",
    "total_revenue = df[df['Booking Status'] == 'Completed']['Booking Value'].sum()\n",
    "avg_booking_value = df[df['Booking Status'] == 'Completed']['Booking Value'].mean()\n",
    "\n",
    "# Key metrics summary\n",
    "print(f\"📊 KEY PERFORMANCE INDICATORS:\")\n",
    "print(f\"   • Total Bookings Processed: {total_bookings:,}\")\n",
    "print(f\"   • Service Completion Rate: {completion_rate:.1f}%\")\n",
    "print(f\"   • Total Revenue Generated: ₹{total_revenue:,.0f}\")\n",
    "print(f\"   • Average Booking Value: ₹{avg_booking_value:.0f}\")\n",
    "\n",
    "# Performance assessment\n",
    "performance_grade = \"A\" if completion_rate >= 75 else \"B\" if completion_rate >= 65 else \"C\"\n",
    "print(f\"   • Overall Performance Grade: {performance_grade}\")\n",
    "\n",
    "print(f\"\\n🚀 IMMEDIATE ACTION PLAN (0-3 MONTHS):\")\n",
    "if completion_rate < 70:\n",
    "    print(f\"   1. ⚡ URGENT: Improve completion rate from {completion_rate:.1f}% to 75%\")\n",
    "    print(f\"      - Implement driver incentives during peak hours\")\n",
    "    print(f\"      - Optimize driver-customer matching algorithms\")\n",
    "    print(f\"      - Launch emergency driver recruitment drive\")\n",
    "else:\n",
    "    print(f\"   1. ✅ MAINTAIN: Current completion rate of {completion_rate:.1f}% is strong\")\n",
    "    print(f\"      - Focus on reducing turn-around times\")\n",
    "    print(f\"      - Optimize route efficiency\")\n",
    "\n",
    "print(f\"   2. 💰 REVENUE OPTIMIZATION:\")\n",
    "print(f\"      - Implement dynamic pricing during peak hours\")\n",
    "print(f\"      - Launch premium service tiers for high-value routes\")\n",
    "print(f\"      - Introduce surge pricing on weekends\")\n",
    "\n",
    "print(f\"   3. 📱 CUSTOMER EXPERIENCE:\")\n",
    "print(f\"      - Reduce average wait times through better driver allocation\")\n",
    "print(f\"      - Implement real-time tracking improvements\")\n",
    "print(f\"      - Launch customer feedback response system\")\n",
    "\n",
    "print(f\"\\n📈 MEDIUM-TERM INITIATIVES (3-12 MONTHS):\")\n",
    "print(f\"   1. 🎯 MARKET EXPANSION:\")\n",
    "print(f\"      - Expand driver network in high-demand areas\")\n",
    "print(f\"      - Launch new vehicle categories based on demand analysis\")\n",
    "print(f\"      - Implement geo-targeted marketing campaigns\")\n",
    "\n",
    "print(f\"   2. 📊 DATA-DRIVEN OPERATIONS:\")\n",
    "print(f\"      - Deploy demand forecasting models\")\n",
    "print(f\"      - Implement predictive maintenance for fleet\")\n",
    "print(f\"      - Launch automated quality monitoring systems\")\n",
    "\n",
    "print(f\"   3. 💡 INNOVATION INITIATIVES:\")\n",
    "print(f\"      - Pilot autonomous dispatch optimization\")\n",
    "print(f\"      - Implement AI-powered customer support\")\n",
    "print(f\"      - Launch subscription-based loyalty programs\")\n",
    "\n",
    "print(f\"\\n🎖️ LONG-TERM STRATEGIC VISION (1+ YEARS):\")\n",
    "print(f\"   • Achieve market leadership in NCR region\")\n",
    "print(f\"   • Expand to adjacent metropolitan markets\")\n",
    "print(f\"   • Launch integrated mobility platform\")\n",
    "print(f\"   • Implement sustainability initiatives (electric vehicles)\")\n",
    "\n",
    "print(f\"\\n📋 SUCCESS METRICS & MONITORING:\")\n",
    "print(f\"   • Target completion rate: >80%\")\n",
    "print(f\"   • Target revenue growth: 25% YoY\")\n",
    "print(f\"   • Target customer satisfaction: >4.5/5.0\")\n",
    "print(f\"   • Target market share: 35% in NCR\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"📋 ANALYSIS COMPLETE - Ready for Executive Presentation\")\n",
    "print(f\"📧 Contact: Data Analytics Team for detailed implementation support\")\n",
    "print(f\"🔄 Next Review: Quarterly performance assessment recommended\")\n",
    "print(f\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}